{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pic\\pie_chair_01.jpg\n",
      "(1792,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "# Loads the JPEG image at the given path\n",
    "# Decodes the JPEG image to a uint8 W X H X 3 tensor\n",
    "# Resizes the image to 224 x 224 x 3 tensor\n",
    "# Returns the pre processed image as 224 x 224 x 3 tensor\n",
    "\n",
    "def load_img(path):\n",
    " # Reads the image file and returns data type of string\n",
    " img = tf.io.read_file(path)\n",
    " # Decodes the image to W x H x 3 shape tensor with type of uint8\n",
    " img = tf.io.decode_jpeg(img, channels=3)\n",
    " # Resizes the image to 224 x 224 x 3 shape tensor\n",
    " img = tf.image.resize_with_pad(img, 224, 224)\n",
    " # Converts the data type of uint8 to float32 by adding a new axis\n",
    " # img becomes 1 x 224 x 224 x 3 tensor with data type of float32\n",
    " # This is required for the mobilenet model we are using\n",
    " img = tf.image.convert_image_dtype(img,tf.float32)[tf.newaxis, ...]\n",
    " \n",
    " return img\n",
    "\n",
    "# Loads the mobilenet model in TF.HUB\n",
    "# Makes an inference for all images stored in a local folder\n",
    "# Saves each of the feature vectors in a file\n",
    "\n",
    "def get_image_feature_vectors():\n",
    " \n",
    " # Definition of module with using tfhub.dev\n",
    " module_handle = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\"\n",
    " # Loads the module\n",
    " module = hub.load(module_handle)\n",
    " # Loops through all images in a local folder\n",
    " for filename in glob.glob('pic/*.jpg'):\n",
    " \n",
    "  print(filename)\n",
    "  # Loads and pre-process the image\n",
    "  img = load_img(filename)\n",
    "  # Calculate the image feature vector of the img\n",
    "  features = module(img)\n",
    "  # Remove single-dimensional entries from the 'features' array  \n",
    "  feature_set = np.squeeze(features)\n",
    "  print(feature_set.shape)\n",
    "  # Saves the image feature vectors into a file for later use\n",
    "  outfile_name = os.path.basename(filename) + \".npz\"\n",
    "  out_path = os.path.join('output/', outfile_name)\n",
    "  # Saves the 'feature_set' to a text file\n",
    "  np.savetxt(out_path, feature_set, delimiter=',')\n",
    "\n",
    "get_image_feature_vectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_handle = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\"\n",
    "module = hub.load(module_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.02288028, 1.3349519 , 0.        , ..., 0.01153526, 0.        ,\n",
       "       0.90349376], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "img = load_img('pic/pie_chair_01.jpg')\n",
    "features = module(img)\n",
    "target_image = np.squeeze(features)\n",
    "target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.18597327, 0.4929459 , 0.        , ..., 0.31545338, 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "img = load_img('datas/bed_13110.png')\n",
    "features = module(img)\n",
    "input_image = np.squeeze(features)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'코사인 유사도 : 0.6705036759376526'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "def cos_sim(A, B):\n",
    "       return \"코사인 유사도 : {}\".format(dot(A, B)/(norm(A)*norm(B)))\n",
    "cos_sim(target_image, input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}